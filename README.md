# Реализации поиска документов по слову в СУБД Firebird

Как известно в Firebird отсутствует функция полнотекстового поиска. В качестве альтернативы обычно предлагается использовать внешне движки полнотекстового поиска такие как Sphinx, Lucence, Solr. Задача интеграции внешних движков поиска довольно не простая, но вполне решаема. Однако во многих случаях можно обойтись более простой альтернативой, если необходимо только искать отдельные слова в тексте документа.

Важно. Пример подготовлен на базе данных где набор символов по умолчанию UTF8.

Предположим у вас есть таблица DOCS с полем TXT типа `BLOB SUB_TYPE TEXT`, в котором находится содержимое документа. 

```sql
CREATE TABLE DOCS (
    ID       BIGINT GENERATED BY DEFAULT AS IDENTITY,
    NAME     VARCHAR(100) NOT NULL,
    SUBNAME  VARCHAR(100),
    TXT      BLOB SUB_TYPE TEXT,
    CONSTRAINT PK_DOCS PRIMARY KEY (ID)
);

COMMENT ON TABLE DOCS IS 'Документы';

COMMENT ON COLUMN DOCS.ID IS 'Идентификатор';
COMMENT ON COLUMN DOCS.NAME IS 'Наименование документа';
COMMENT ON COLUMN DOCS.SUBNAME IS 'Подзаголовок';
COMMENT ON COLUMN DOCS.TXT IS 'Текст документа';
```

Для реализации поика документа по слову предлагается создать таблицу-словарь DICT_WORDS и таблицу со ссылками на документ и слово из словаря DOC_WORDS.

```sql
CREATE TABLE DICT_WORDS (
    ID   BIGINT GENERATED BY DEFAULT AS IDENTITY,
    TXT  VARCHAR(150) NOT NULL COLLATE UNICODE_CI,
    CONSTRAINT PK_DICT_WORDS PRIMARY KEY (ID),
    CONSTRAINT UK_DICT_WORDS UNIQUE (TXT)
);

COMMENT ON TABLE DICT_WORDS IS 'Словарь слов';
COMMENT ON COLUMN DICT_WORDS.ID IS 'Идентификатор слова';
COMMENT ON COLUMN DICT_WORDS.TXT IS 'Слово';

CREATE TABLE DOC_WORDS (
    ID       BIGINT GENERATED BY DEFAULT AS IDENTITY,
    DOC_ID   BIGINT NOT NULL,
    WORD_ID  BIGINT NOT NULL,
    CONSTRAINT PK_DOC_WORDS PRIMARY KEY (ID),
    CONSTRAINT FK_DOC_WORDS_REF_DOC FOREIGN KEY (DOC_ID) 
      REFERENCES DOCS (ID) ON DELETE CASCADE,
    CONSTRAINT FK_DOC_WORDS_REF_WORD 
      FOREIGN KEY (WORD_ID) REFERENCES DICT_WORDS (ID)
);

COMMENT ON TABLE DOC_WORDS IS 'Слова внутри документа';

COMMENT ON COLUMN DOC_WORDS.ID IS 'Идентификатор';
COMMENT ON COLUMN DOC_WORDS.DOC_ID IS 'Ссылка на документа';
COMMENT ON COLUMN DOC_WORDS.WORD_ID IS 'Ссылка на слово в словаре';
```

Содержимое таблиц DICT_WORDS и DOC_WORDS будет поддерживаться с помощью триггеров AFTER INSERT и AFTER UPDATE на таблице DOCS. При добавлении нового документа, его содержимое разбивается на отдельные слова, эти слова добавляются в словарь если их нет, и добавляется ссылка на слово в словаре и на идентификатор документа. 

Перед тем как приступить к реализации триггеров необходимо написать хранимую процедуру разбиения содержимого документа на отдельные слова. Сразу скажу обработка полей типа BLOB на процедурном языке PSQL будет не эффективной. Однако, начиная с Firebird 3.0 мы можем писать хранимые процедуры на внешних языках программирования. Для этих целей я написал хранимую процедуру разбиения текста на отдельные слова на языке C++.

Процедура разбиения текста на слова имеет два входных параметра: 

* `TXT BLOB SUB_TYPE TEXT` - текст для разбора
* `SEPARATORS VARCHAR(50) = NULL` - строка со списком разделителей. По умолчанию разделителями являются следующий набор символов " \n\r\t,.?!:;/\\|<>[]{}()@#$%^&*-+='\"~`"

Первым делом реализуем более простую процедуру разбиения текста с типом `VARCHAR` на слова по списку разделителей.

```cpp
/***
create procedure split_words_s (
	in_txt varchar(8191) character set utf8,
	in_separators varchar(50) character set utf8 default null
) returns (
	out_txt varchar(8191) character set utf8
)
	external name 'splitudr!strtok_s'
	engine udr;
***/
FB_UDR_BEGIN_PROCEDURE(strtok_s)
FB_UDR_MESSAGE(InMessage,
	(FB_VARCHAR(32765), txt)
	(FB_VARCHAR(255), separators)
);

FB_UDR_MESSAGE(OutMessage,
	(FB_VARCHAR(32765), txt)
);

FB_UDR_EXECUTE_PROCEDURE
{
	if (in->txtNull)
	{
		stopFlag = true;
		out->txtNull = FB_TRUE;
		out->txt.length = 0;
	}
	else
	{
		str.assign(in->txt.str, in->txt.length);

		if (in->separatorsNull) {
			separators = " \n\r\t,.?!:;/\\|<>[]{}()@#$%^&*-+='\"~`";
		}
		else
		   separators.assign(in->separators.str, in->separators.length);

	}
}


std::string str;
std::string separators;
size_t prev = 0;
size_t next = 0;
bool stopFlag = false;

FB_UDR_FETCH_PROCEDURE
{
	if (stopFlag)
	{
		return false;
	}
	out->txtNull = FB_FALSE;
	// ищем первый из символов separators в строке str начиная с позиции prev
	while ((next = str.find_first_of(separators, prev)) != std::string::npos) {
		// пока находим в строке разделитель
		// возвращаем строки между разделителями	
		const size_t length = next - prev;
		// если строка получилась пустой ищем следующий разделитель
		if (length == 0) {
			prev = next + 1;
			continue;
		}
		// копируем результат в выходное сообщение
		out->txt.length = length;
		str.copy(out->txt.str, out->txt.length, prev);

		prev = next + 1;
		return true;
	}
	// ни одного разделителя не найдено, 
	// словом является строка от предыдущего разделителя и до конца строки str
	next = str.length();

	const size_t length = next - prev;
	// если строка получилась пустой значит результат не возвращаем
	if (length == 0) {
		return false;
	}
    // копируем результат в выходное сообщение
	out->txt.length = length;
	str.copy(out->txt.str, out->txt.length, prev);
	prev = next + 1;
	// инициализация флага остановки
	stopFlag = prev >= str.length();
	return true;

}
FB_UDR_END_PROCEDURE
```

Теперь напишем процедуру разбиения текста с типом `BLOB SUB_TYPE TEXT` на слова по списку разделителей. Можно пойти простым путём, а именно считать весь BLOB целиком в строку типа `std::string` и далее оставить алгоритм как в strtok_s. Однако такая реализация обладает двумя недостатками:

1. Повышенное потребление памяти (всё содержимое BLOB. а он может быть большой копируется в строку);
2. Пока весь BLOB не будет прочитан в строку вы не сможете прервать выполнение процедуры.

Для решения этих проблем предполагается читать BLOB частями, обрабатывать каждую часть (разбивать её по разделителями) и вновь читать следующую часть BLOB.

```cpp
/***
create procedure split_words (
	in_txt blob sub_type text character set utf8,
	in_separators varchar(50) character set utf8 default null
) returns (
	out_txt varchar(8191) character set utf8
)
	external name 'splitudr!strtok'
	engine udr;
***/
FB_UDR_BEGIN_PROCEDURE(strtok)
FB_UDR_MESSAGE(InMessage,
	(FB_BLOB, txt)
	(FB_VARCHAR(255), separators)
);

FB_UDR_MESSAGE(OutMessage,
	(FB_VARCHAR(32765), txt)
);

FB_UDR_EXECUTE_PROCEDURE
{
	if (in->txtNull)
	{
		stopFlag = true;
		out->txtNull = FB_TRUE;
		out->txt.length = 0;
	}
	else
	{
		if (in->separatorsNull) {
			separators = " \n\r\t,.?!:;/\\|<>[]{}()@#$%^&*-+='\"~`";
		}
		else
		   separators.assign(in->separators.str, in->separators.length);

		att.reset(context->getAttachment(status));
		tra.reset(context->getTransaction(status));

		blob.reset(att->openBlob(status, tra, &in->txt, 0, nullptr));
		// читаем первые ~32Kбайт
		std::stringstream ss("");
		for (int n = 0; !eof && n < 32765; ) {
			char buffer[32765];
			unsigned int l = 0;
			switch (blob->getSegment(status, sizeof(buffer), &buffer[0], &l))
			{
				case IStatus::RESULT_OK:
				case IStatus::RESULT_SEGMENT:
					ss.write(buffer, l);
					n += l;
					continue;
				default:
					blob->close(status);
					eof = true;
					break;
			}
		}
		str = ss.str();
	}
}


AutoRelease<IAttachment> att;
AutoRelease<ITransaction> tra;
AutoRelease<IBlob> blob;


std::string str;
std::string separators;
size_t prev = 0;
size_t next = 0;
bool stopFlag = false;
bool eof = false;

FB_UDR_FETCH_PROCEDURE
{
	if (stopFlag)
	{
		return false;
	}
	out->txtNull = FB_FALSE;
	// ищем первый из символов separators в строке str начиная с позиции prev
	while ((next = str.find_first_of(separators, prev)) != std::string::npos) {
		// пока находим в строке разделитель
		// возвращаем строки между разделителями	
		const size_t length = next - prev;
		// если строка получилась пустой ищем следующий разделитель
		if (length == 0) {
			prev = next + 1;
			continue;
		}
		if (length > 32765) {
			ISC_STATUS statusVector[] = {
				 isc_arg_gds, isc_random,
				 isc_arg_string, (ISC_STATUS)"Output buffer overflow",
				 isc_arg_end
			};
			throw Firebird::FbException(status, statusVector);
		}
		// копируем результат в выходное сообщение
		out->txt.length = length;
		str.copy(out->txt.str, out->txt.length, prev);
		
		prev = next + 1;
		return true;
	}
	// строка после последнего разделителя не обязательно полная,
	// разделитель может быть в не прочитанной части BLOB
	if (!eof) {
		// если BLOB прочитан не полностью, то
		// читаем следующие ~32Kбайт
		std::stringstream ss("");
		for (int n = 0; !eof && n < 32765; ) {
			char buffer[32765];
			unsigned int l = 0;
			switch (blob->getSegment(status, sizeof(buffer), &buffer[0], &l))
			{
		 	    case IStatus::RESULT_OK:
				case IStatus::RESULT_SEGMENT:
					ss.write(buffer, l);
					n += l;
					continue;
				default:
					blob->close(status);
					eof = true;
					break;
			}
		}
		// удаляем из строки всё кроме части
		// после последнего разделителя
		str.erase(0, prev);
		prev = 0;
		// и добавляем в неё прочитанной из BLOB
		str.append(ss.str());

		// ищем первый из символов separators в строке str начиная с позиции prev
		next = str.find_first_of(separators, prev);
		if (next == std::string::npos)
			next = str.length();
	}
	else {
		next = str.length();
	}
	while (true) {
		const size_t length = next - prev;
		// если строка получилась пустой ищем следующий разделитель
		if (length == 0) {
			prev = next + 1;
			next = str.find_first_of(separators, prev);
			if (next != std::string::npos)
				continue;
			else
				return false;
		}
		if (length > 32765) {
			ISC_STATUS statusVector[] = {
				 isc_arg_gds, isc_random,
				 isc_arg_string, (ISC_STATUS)"Output buffer overflow",
				 isc_arg_end
			};
			throw Firebird::FbException(status, statusVector);
		}
		// копируем результат в выходное сообщение
		out->txt.length = length;
		str.copy(out->txt.str, out->txt.length, prev);
		prev = next + 1;
		// инициализация флага остановки
		stopFlag = eof && prev >= str.length();
		return true;
	}
}
FB_UDR_END_PROCEDURE
```

Хранимые процедуры для разбиения текста на слова объявлены следующим образом:

```sql
CREATE OR ALTER PROCEDURE SPLIT_WORDS (
    IN_TXT        BLOB SUB_TYPE TEXT CHARACTER SET UTF8,
    IN_SEPARATORS VARCHAR(50) CHARACTER SET UTF8 DEFAULT NULL)
RETURNS (
    WORD VARCHAR(8191) CHARACTER SET UTF8)
EXTERNAL NAME 'splitudr!strtok' ENGINE UDR;

CREATE OR ALTER PROCEDURE SPLIT_WORDS_S (
    IN_TXT        VARCHAR(8191) CHARACTER SET UTF8,
    IN_SEPARATORS VARCHAR(50) CHARACTER SET UTF8 DEFAULT NULL)
RETURNS (
    WORD VARCHAR(8191) CHARACTER SET UTF8)
EXTERNAL NAME 'splitudr!strtok_s' ENGINE UDR;
```

Для тестирования процедуры SPLIT_WORDS я пробовал разобрать на отдельные слова 4 тома романа "Война и мир". Процедура отработала за 2.5 секунды, что я считаю довольно не плохим результатом.

Исходный код библиотеки SplitUDR которая содержит данные процедуры расположен по адресу https://github.com/sim1984/split_udr

Теперь можно приступать к написанию триггеров для поддержания словаря и таблицы ссылок документа на слова.

```sql
SET TERM ^ ;

CREATE OR ALTER TRIGGER TR_DOCS_AI FOR DOCS
ACTIVE AFTER INSERT POSITION 0
AS
DECLARE WORD VARCHAR(150);
DECLARE WORD_ID BIGINT;
BEGIN
  -- разбиваем текст на слова
  FOR
    SELECT W.WORD, DW.ID
    FROM (SELECT WORD COLLATE UNICODE_CI AS WORD
          FROM SPLIT_WORDS(NEW.TXT)
          GROUP BY WORD COLLATE UNICODE_CI) W
    LEFT JOIN DICT_WORDS DW ON DW.TXT = W.WORD
    INTO WORD, WORD_ID
  DO
  BEGIN
    -- если слова нет, то добавляем его
    IF (WORD_ID IS NULL) THEN
    BEGIN
      INSERT INTO DICT_WORDS(TXT)
      VALUES (:WORD)
      RETURNING ID INTO WORD_ID;
    END

    -- вставляем ссылку на слово
    INSERT INTO DOC_WORDS(DOC_ID, WORD_ID)
    VALUES (NEW.ID, :WORD_ID);
  END
END
^

CREATE OR ALTER TRIGGER TR_DOCS_AU FOR DOCS
ACTIVE AFTER UPDATE POSITION 0
AS
DECLARE WORD VARCHAR(150);
DECLARE WORD_ID BIGINT;
BEGIN
  -- только если текст поменялся
  IF (NEW.TXT IS DISTINCT FROM OLD.TXT) THEN
  BEGIN
    -- удаляем все ссылки на слова предыдущего текста
    DELETE FROM DOC_WORDS
    WHERE DOC_WORDS.DOC_ID = OLD.ID;

    -- разбиваем новый текст на слова
    FOR
      SELECT W.WORD, DW.ID
      FROM (SELECT WORD COLLATE UNICODE_CI AS WORD
            FROM SPLIT_WORDS(NEW.TXT)
            GROUP BY WORD COLLATE UNICODE_CI) W
      LEFT JOIN DICT_WORDS DW ON DW.TXT = W.WORD
      INTO WORD, WORD_ID
    DO
    BEGIN
      -- если слова нет, то добавляем его
      IF (WORD_ID IS NULL) THEN
      BEGIN
        INSERT INTO DICT_WORDS(TXT)
        VALUES (:WORD)
        RETURNING ID INTO WORD_ID;
      END

      -- вставляем ссылку на слово
      INSERT INTO DOC_WORDS(DOC_ID, WORD_ID)
      VALUES (NEW.ID, :WORD_ID);
    END
  END
END
^

SET TERM ; ^
```

Теперь напишем процедуру поиска документа по слову. На вход процедуры поступает слово для поиска, а на выходе список идентификаторов документов, в которых это слово присутствует.

```sql
SET TERM ^ ;

CREATE OR ALTER PROCEDURE FIND_DOC_BY_WORD (
    AWORD VARCHAR(150))
RETURNS (
    DOC_ID BIGINT)
AS
BEGIN
  FOR
      SELECT
          DOC_WORDS.DOC_ID
      FROM DICT_WORDS
          JOIN DOC_WORDS ON
                DOC_WORDS.WORD_ID = DICT_WORDS.ID
      WHERE DICT_WORDS.TXT = :AWORD COLLATE UNICODE_CI
      GROUP BY 1
      INTO DOC_ID
  DO
    SUSPEND;
END
^

SET TERM ; ^
```

Пример использования процедуры FIND_DOC_BY_WORD:

```sql
SELECT
    DOCS.*
FROM FIND_DOC_BY_WORD('лицо') W
    JOIN DOCS ON
          DOCS.ID = W.DOC_ID   
```
